{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils, print_summary\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11000 images belonging to 11 classes.\n",
      "Found 2200 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 100\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "          'data/train',\n",
    "          target_size=(50, 50),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='categorical',  # this means our generator will only yield batches of data, no labels\n",
    "          shuffle=True,\n",
    "          color_mode='grayscale',\n",
    "          classes=['1','2','3','4','5','6','7','8','9','10','11'])\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "          'data/test',\n",
    "          target_size=(50, 50),\n",
    "          batch_size=batch_size,\n",
    "          class_mode='categorical',  # this means our generator will only yield batches of data, no labels\n",
    "          shuffle=True,\n",
    "          color_mode='grayscale',\n",
    "          classes=['1','2','3','4','5','6','7','8','9','10','11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x7f3a2b28fba8>\n"
     ]
    }
   ],
   "source": [
    "#version1 is the best :)_\n",
    "model1 = load_model('hand_emoji_v5.h5')\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  0\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "batch:  1\n",
      "batch:  2\n",
      "batch:  3\n",
      "batch:  4\n",
      "batch:  5\n",
      "batch:  6\n",
      "batch:  7\n",
      "batch:  8\n",
      "batch:  9\n",
      "batch:  10\n",
      "batch:  11\n",
      "batch:  12\n",
      "batch:  13\n",
      "batch:  14\n",
      "batch:  15\n",
      "batch:  16\n",
      "batch:  17\n",
      "batch:  18\n",
      "batch:  19\n",
      "batch:  20\n",
      "batch:  21\n"
     ]
    }
   ],
   "source": [
    "batch = 0 \n",
    "x_generator = None\n",
    "y_lable = None\n",
    "for x,y in validation_generator:\n",
    "    if batch == (2200/batch_size):\n",
    "        break\n",
    "    print(\"batch: \", batch)\n",
    "    batch += 1\n",
    "    if np.any(x_generator) == None:\n",
    "        x_generator = model1.predict_on_batch(x)\n",
    "        y_lable = y\n",
    "        print(y)\n",
    "    else:\n",
    "        x_generator = np.append(x_generator,model1.predict_on_batch(x),axis=0)\n",
    "        y_lable = np.append(y_lable,y,axis=0)\n",
    "x_generator,y_lable = shuffle(x_generator,y_lable)\n",
    "np.save('video_x_validate_VGG16.npy',x_generator)\n",
    "np.save('video_y_validate_VGG16.npy',y_lable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('video_x_validate_VGG16.npy', mmap_mode='r')\n",
    "train_labels = np.load('video_y_validate_VGG16.npy', mmap_mode='r')\n",
    "train_data,train_labels = shuffle(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f01a99cfb5fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train_data = train_data.reshape(train_data.shape[0],\n\u001b[0;32m----> 2\u001b[0;31m                 \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                 train_data.shape[3])\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "train_data = train_data.reshape(train_data.shape[0],\n",
    "                train_data.shape[1] * train_data.shape[2],\n",
    "                train_data.shape[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
