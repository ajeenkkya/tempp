{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils, print_summary\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras import regularizers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2501)\n",
      "(2000, 2501)\n"
     ]
    }
   ],
   "source": [
    "training_images = 1000\n",
    "testing_images = 2200\n",
    "\n",
    "train_datadir = \"data/train\"\n",
    "test_datadir = \"data/test\"\n",
    "categories = {1:\"1\", 2:\"2\", 3:\"3\", 4:\"4\", 5:\"5\", 6:\"6\", 7:\"7\", 8:\"8\", 9:\"9\", 10:\"10\", 11:\"11\"}\n",
    "train_dataset = np.zeros(shape=(training_images,2501))\n",
    "test_dataset = np.zeros(shape=(testing_images,2501))\n",
    "\n",
    "counter = 0\n",
    "for category in categories:\n",
    "    path = os.path.join(train_datadir,categories[category])\n",
    "    label = np.array([category])\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            image = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (50,50))\n",
    "            te = image.flatten()\n",
    "            te = np.array(te)\n",
    "            te = np.concatenate((te, label), axis=0)\n",
    "            te = np.array(te)[np.newaxis]\n",
    "            #cv2.imwrite(\"newfan\"+str(i)+\".jpg\",image)\n",
    "            train_dataset[counter] = te\n",
    "            counter = counter + 1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "counter = 0\n",
    "for category in categories:\n",
    "    path = os.path.join(test_datadir,categories[category])\n",
    "    label = np.array([category])\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            image = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (50,50))\n",
    "            te = image.flatten()\n",
    "            te = np.array(te)\n",
    "            te = np.concatenate((te, label), axis=0)\n",
    "            te = np.array(te)[np.newaxis]\n",
    "            #cv2.imwrite(\"newfan\"+str(i)+\".jpg\",image)\n",
    "            test_dataset[counter] = te\n",
    "            counter = counter + 1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "print(train_dataset.shape)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_dataset)\n",
    "np.random.shuffle(test_dataset)\n",
    "\n",
    "X_train = train_dataset[:, 0:2500]\n",
    "Y_train = train_dataset[:, 2500]\n",
    "\n",
    "x_test = test_dataset[:, 0:2500]\n",
    "Y_test = test_dataset[:, 2500]\n",
    "\n",
    "x_train = X_train/255\n",
    "\n",
    "Y_train = Y_train.reshape(Y_train.shape[0], 1)\n",
    "y_train = Y_train.T\n",
    "\n",
    "Y_test = Y_test.reshape(Y_test.shape[0], 1)\n",
    "y_test = Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are taking an image of 32x32 for training purpose\n",
    "image_x = 50\n",
    "image_y = 50\n",
    "#to_categorical is an function which converts a matrix to a vector; in our case it basically gets the label which is an integer\n",
    "#and changes it to form of one_hot_encoding.\n",
    "#Check this link for more details->https://keras.io/utils/\n",
    "train_y = np_utils.to_categorical(y_train, dtype='int32')\n",
    "test_y = np_utils.to_categorical(y_test, dtype='int32')\n",
    "#adjusting the shape\n",
    "train_y = train_y.reshape(train_y.shape[1], train_y.shape[2])\n",
    "test_y = test_y.reshape(test_y.shape[1], test_y.shape[2])\n",
    "x_train = x_train.reshape(x_train.shape[0], image_x, image_y, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], image_x, image_y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "(2000, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test_y[1])\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "def keras_model(image_x, image_y):\n",
    "    num_of_classes = 12\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=8, kernel_size=(3,3), input_shape=(image_x, image_y, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(3,3), padding='same'))\n",
    "    model.add(Conv2D(64, (5,5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(3,3), padding='same'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.007)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    #saving the trained data is saved here\n",
    "    filepath='hand_emoji_v5.h5'\n",
    "    checkpoint1 = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint1]\n",
    "    #returning the model and the checkpoints of the saved(learned) data\n",
    "    return model, callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 3.5297 - acc: 0.9527 - val_loss: 2.0853 - val_acc: 0.9695\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.08525, saving model to hand_emoji_v5.h5\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.9583 - acc: 0.9950 - val_loss: 2.3347 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.08525\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.4642 - acc: 0.9907 - val_loss: 1.9112 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.08525 to 1.91119, saving model to hand_emoji_v5.h5\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.2870 - acc: 0.9932 - val_loss: 2.0546 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.91119\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2620 - acc: 0.9911 - val_loss: 0.4465 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.91119 to 0.44652, saving model to hand_emoji_v5.h5\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.2236 - acc: 0.9930 - val_loss: 0.3422 - val_acc: 0.9880\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.44652 to 0.34217, saving model to hand_emoji_v5.h5\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.1890 - acc: 0.9918 - val_loss: 2.0972 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34217\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.1793 - acc: 0.9939 - val_loss: 0.2203 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.34217 to 0.22029, saving model to hand_emoji_v5.h5\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.1760 - acc: 0.9944 - val_loss: 0.2090 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.22029 to 0.20901, saving model to hand_emoji_v5.h5\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.1664 - acc: 0.9957 - val_loss: 0.2478 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20901\n",
      "CNN error: 0.55%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 64)        12864     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 675,484\n",
      "Trainable params: 673,820\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, callbacks_list = keras_model(image_x, image_y)\n",
    "model.fit(x_train, train_y, validation_data=(x_test, test_y), epochs=10, batch_size=64, callbacks=callbacks_list)\n",
    "scores = model.evaluate(x_test, test_y, verbose=0)\n",
    "print(\"CNN error: %.2f%%\" %(100 - scores[1] * 100))\n",
    "print_summary(model)\n",
    "model.save('hand_emoji_v5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
